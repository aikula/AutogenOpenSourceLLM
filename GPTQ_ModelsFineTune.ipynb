{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6751810-eab5-48a5-9ef0-c3e9dbca385e",
   "metadata": {},
   "source": [
    "https://dsmonk.medium.com/training-and-deploying-of-quantized-llms-with-lora-and-gptq-part-2-2-ec7b54659c9e\n",
    "\n",
    "Потребность памяти 11Gb, 13Gb для датасетя 5000/1024\n",
    "\n",
    "Обучение на диалогах.\n",
    "\n",
    "Обратить внимание на ###end\n",
    "\n",
    "Разбирать ответ по тегам, хорошо работает вопрос + Response. В этом случае ловить надо end of response\n",
    "\n",
    "\n",
    "watch -d -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a1ec2-9841-46a2-a96e-861585e45a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U transformers peft accelerate optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f3f18a-2b9b-40e4-ae32-e31e24a6299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu117/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056a3803-49ca-48ac-b89c-accbbcd68f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e190f6-e9e1-4d46-a4a7-b8c7115563d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty VRAM cache\n",
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9444a097-2547-415a-a78e-8ddb9d1069af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device_string = \"cuda:\" + str(local_rank)\n",
    "#kwargs[\"device_map\"] = device_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb2501c-75eb-4586-83e4-ea123d02e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"false\"\n",
    "\n",
    "#from huggingface_hub import login\n",
    "#login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7d057-194a-4b01-a536-da59d71fade3",
   "metadata": {},
   "source": [
    "# Чужой датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6352edb-282a-4437-a7a6-af5a37470a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "#train_ds, test_ds = load_dataset(\"knkarthick/dialogsum\", split=[\"train\", \"test[0:200]\"])\n",
    "#dataset = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8892215a-9fd8-4d5b-849e-f3b0dba7b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b6d6ad-898d-478c-9144-58eaf4af055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# convert to pandas\n",
    "train_df = pd.DataFrame(train_ds)\n",
    "test_df = pd.DataFrame(test_ds)\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff93d6-17de-462b-8c5b-30f509eefb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# instruction finetuning data preparation function\n",
    "\n",
    "# тестовый датасет идет без ### End\n",
    "\n",
    "def prepare_dataset(df, split=\"train\"):\n",
    "    text_col = []\n",
    "    instruction = \"\"\"Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only provide full sentence responses.\"\"\"  # change instuction according to the task\n",
    "    if split == \"train\":\n",
    "        for _, row in df.iterrows():\n",
    "            input_q = row[\"dialogue\"]\n",
    "            output = row[\"summary\"]\n",
    "            text = (\n",
    "                \"### Instruction: \\n\"\n",
    "                + instruction\n",
    "                + \"\\n### Input: \\n\"\n",
    "                + input_q\n",
    "                + \"\\n### Response :\\n\"\n",
    "                + output\n",
    "                + \"\\n### End\"\n",
    "            )  # keeping output column in training dataset\n",
    "            text_col.append(text)\n",
    "        df.loc[:, \"text\"] = text_col\n",
    "    else:\n",
    "        for _, row in df.iterrows():\n",
    "            input_q = row[\"dialogue\"]\n",
    "            text = (\n",
    "                \"### Instruction: \\n\"\n",
    "                + instruction\n",
    "                + \"\\n### Input: \\n\"\n",
    "                + input_q\n",
    "                + \"\\n### Response :\\n\"\n",
    "            )  # not keeping output column in test dataset\n",
    "            text_col.append(text)\n",
    "        df.loc[:, \"text\"] = text_col\n",
    "    return df\n",
    "\n",
    "train_df = prepare_dataset(train_df, \"train\")\n",
    "test_df = prepare_dataset(test_df, \"test\")\n",
    "print(train_df.iloc[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d3b374-418a-409f-9308-1c38aa66b007",
   "metadata": {},
   "source": [
    "# My Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b949d588-4174-4684-8d23-62393bc34a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('srv/result_dataset.json', 'r') as f:\n",
    "    j=json.load(f)\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(j)\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91171881-72c5-4e2a-8133-565217b0ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df):\n",
    "    text_col = []\n",
    "    instruction = \"\"\"Ответь на вопрос. \"\"\"  # change instuction according to the task\n",
    "    for _, row in df.iterrows():\n",
    "        input_q = row[\"question\"]\n",
    "        output = row[\"answer\"]\n",
    "        text = (\n",
    "            \"### Instruction: \\n\"\n",
    "            + instruction\n",
    "            + \"\\n### Input: \\n\"\n",
    "            + input_q\n",
    "            + \"\\n### Response :\\n\"\n",
    "            + output\n",
    "            + \"\\n### End\"\n",
    "            )  # keeping output column in training dataset\n",
    "        text_col.append(text)\n",
    "    df.loc[:, \"text\"] = text_col\n",
    "    return df\n",
    "\n",
    "train_df = prepare_dataset(df)\n",
    "print(train_df.iloc[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1000af9-1317-4ab4-90b8-e2e68adb37d0",
   "metadata": {},
   "source": [
    "# Small INK dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61db0c03-93a1-4b4f-ba4c-ce4c75f23e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Наименование Групп (Папок) нижнего уровня соот...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3928</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21. Отчет «Контроль исполнения заявок системой...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4385</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Рисунок 13. Заявка на оплату – Бивалютный плат...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     instruction                                             output input\n",
       "2487         NaN  Наименование Групп (Папок) нижнего уровня соот...   NaN\n",
       "3928         NaN  21. Отчет «Контроль исполнения заявок системой...   NaN\n",
       "4385         NaN  Рисунок 13. Заявка на оплату – Бивалютный плат...   NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('10K_ink_dataset.txt', sep='|')\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c25b01-235d-4077-a4c6-9922950a56f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[464]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4082fd50-fe4d-4661-a641-ab67b3976d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[:464]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28cedaf9-1ffc-4038-a72b-0dced06fd988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "      <th>input</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1C: УПП ИНК. PM.CostEngineering</td>\n",
       "      <td>Модуль в составе УПП. Решение PM.cost engineer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>### Instruction:\\nОтветь на вопрос максимально...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>1. Какие периоды доступны для ручного редактир...</td>\n",
       "      <td>В заявке по бюджету движения денежных средств ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>### Instruction:\\nОтветь на вопрос максимально...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>2. Какая форма доступна при нажатии на кнопку ...</td>\n",
       "      <td>Форма \"Акт приема-передачи давальческих матери...</td>\n",
       "      <td>В документе \"Передача материалов между подрядч...</td>\n",
       "      <td>### Instruction:\\nОтветь на вопрос максимально...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           instruction  \\\n",
       "115                    1C: УПП ИНК. PM.CostEngineering   \n",
       "444  1. Какие периоды доступны для ручного редактир...   \n",
       "267  2. Какая форма доступна при нажатии на кнопку ...   \n",
       "\n",
       "                                                output  \\\n",
       "115  Модуль в составе УПП. Решение PM.cost engineer...   \n",
       "444  В заявке по бюджету движения денежных средств ...   \n",
       "267  Форма \"Акт приема-передачи давальческих матери...   \n",
       "\n",
       "                                                 input  \\\n",
       "115                                                NaN   \n",
       "444                                                NaN   \n",
       "267  В документе \"Передача материалов между подрядч...   \n",
       "\n",
       "                                                  text  \n",
       "115  ### Instruction:\\nОтветь на вопрос максимально...  \n",
       "444  ### Instruction:\\nОтветь на вопрос максимально...  \n",
       "267  ### Instruction:\\nОтветь на вопрос максимально...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def prepare(row, instruction='Ответь на вопрос максимально точно и лаконично.'):\n",
    "    if pd.notna(row['instruction']):\n",
    "        return f\"\"\"### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{row['instruction']}\n",
    "\n",
    "### Response:\n",
    "{row['output']}\n",
    "\n",
    "### End\"\"\"\n",
    "    else:\n",
    "        # по поводу End в строке надо проверить конечно\n",
    "        return re.sub('\\t', ' ', row['output'])+\"\\n### End\"\n",
    "\n",
    "df['text']=df.apply(lambda x: prepare(x), axis=1)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02c510f3-3efe-44d5-bdb3-b489390dfc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['instruction', 'output', 'input'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e894f38-c62a-482c-b52c-c9fb56e54407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>### Instruction:\\nОтветь на вопрос максимально...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>### Instruction:\\nОтветь на вопрос максимально...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>### Instruction:\\nОтветь на вопрос максимально...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>### Instruction:\\nОтветь на вопрос максимально...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>### Instruction:\\nОтветь на вопрос максимально...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>### Instruction:\\nОтветь на вопрос максимально...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>### Instruction:\\nОтветь на вопрос максимально...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>### Instruction:\\nОтветь на вопрос максимально...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>### Instruction:\\nОтветь на вопрос максимально...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>### Instruction:\\nОтветь на вопрос максимально...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>464 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    ### Instruction:\\nОтветь на вопрос максимально...\n",
       "1    ### Instruction:\\nОтветь на вопрос максимально...\n",
       "2    ### Instruction:\\nОтветь на вопрос максимально...\n",
       "3    ### Instruction:\\nОтветь на вопрос максимально...\n",
       "4    ### Instruction:\\nОтветь на вопрос максимально...\n",
       "..                                                 ...\n",
       "459  ### Instruction:\\nОтветь на вопрос максимально...\n",
       "460  ### Instruction:\\nОтветь на вопрос максимально...\n",
       "461  ### Instruction:\\nОтветь на вопрос максимально...\n",
       "462  ### Instruction:\\nОтветь на вопрос максимально...\n",
       "463  ### Instruction:\\nОтветь на вопрос максимально...\n",
       "\n",
       "[464 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96561895-c87f-4e2a-841d-bafbb8d61ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 464 entries, 0 to 463\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    464 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c54fb65d-7cfc-4558-8008-70ccd5316bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7d9a21-f97e-4d4f-9c16-d728fc90cc8c",
   "metadata": {},
   "source": [
    "# Подготовка и обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b80443fc-9ad9-4f59-9250-3c72a021bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8737b466-e681-48e5-84dd-97f2fcd95805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from transformers import GPTQConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6df7bd13-3766-4ced-a2b7-ff40ef1c735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"TheBloke/Llama-2-7B-GPTQ\"\n",
    "#model_id='TheBloke/Llama-2-13B-GPTQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5ef22e6-8189-4feb-8461-156f1f0fade4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. use_exllama, exllama_config, use_cuda_fp16, max_input_length) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n"
     ]
    }
   ],
   "source": [
    "quantization_config_loading = GPTQConfig(bits=8, use_exllama=False) #disable_exllama=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, quantization_config=quantization_config_loading, device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37a3c27c-cc22-48c6-ab34-88915a16fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "config = LoraConfig(\n",
    "    r= 16, #8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"k_proj\",\"o_proj\",\"q_proj\",\"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e01676e8-928e-45d8-bb6c-4f0550b1b00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16,777,216 || all params: 279,187,456 || trainable%: 6.009301506726721\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()\n",
    "# %%\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "# needed for llama 2 tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "model.config.use_cache = False # silence the warnings. Please re-enable for inference!\n",
    "args=TrainingArguments(\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=1, #4,# чем больше, тем быстрее учится\n",
    "        num_train_epochs=7,\n",
    "        warmup_steps=2,\n",
    "        max_steps=-1,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True, #use mixed precision training\n",
    "        logging_steps=10, #увеличить\n",
    "        output_dir=\"INK_small\",\n",
    "        overwrite_output_dir=True,\n",
    "        save_steps=20,\n",
    "        save_total_limit=2,\n",
    "        optim=\"adamw_hf\",\n",
    "        save_strategy=\"epoch\",\n",
    "        report_to=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea2e76da-83a2-4765-a71a-52dd7acd58f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f684f95331d04bbea778db11571404f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/464 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "# use_reentrant=True\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    packing=False,\n",
    "    max_seq_length=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80e295b1-2729-4bd5-ae17-ed464c49ea7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='812' max='812' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [812/812 13:36, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.818000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.215200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.084800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.141700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.992400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.942600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.083700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.928300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.864700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.811200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.896600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.864600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.807300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.811400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.838300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.871600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.850900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.816400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.693900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.696300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.774900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.570700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.655400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.653200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.614900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.762000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.719700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.685800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.723400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.604900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.554500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.578500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.515600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.565400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.518300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.488800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.569900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.531400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.515500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.565200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.444500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.527200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.402100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.435500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.386600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.352800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.363200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.449400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.474400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.447200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.426200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.405900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.342400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.273700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.376600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.332900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.316400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.311500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.359900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.349800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.278900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.253300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.221800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.231500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.250100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.288500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.233600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.269800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.301300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.304300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.262900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.252600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.231200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da257b7d-26c8-422c-b6e6-e2150c2218d7",
   "metadata": {},
   "source": [
    "# Сохранение адаптера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27472b04-bcf4-4e6a-b88b-e1efb4cb08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "checkpoint_name =\"INK_small\"\n",
    "#to merge and save the model\n",
    "output_dir = os.path.join(args.output_dir, checkpoint_name)\n",
    "trainer.model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c5233-89f2-4437-8ddf-caaa55ed1365",
   "metadata": {},
   "source": [
    "# Чтение и запуск адаптера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b88bad24-cb92-4546-83a1-6abca72fda6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"INK_small/INK_small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e949044f-8d7a-461e-85ed-ac9e57132282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# To perform inference on the test dataset example load the model from the checkpoint\n",
    "persisted_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    output_dir,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\",\n",
    ")\n",
    "\n",
    "model_id = \"TheBloke/Llama-2-7B-GPTQ\"\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# needed for llama 2 tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91b03716-3c84-4b5d-bdd0-1e33dbdcbb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">### Instruction:\n",
       "Ответь на вопрос максимально точно и лаконично.\n",
       "\n",
       "### Input:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Какие данные можно увидеть в нижней части обработки «Карта номерного фонда»?\n",
       "\n",
       "### Response:\n",
       "- В нижней части обработки можно увидеть информацию о проживающем: ФИО, место работы, должность, подразделение, \n",
       "номер заявки или брони на указанный период, даты заезда и выезда, статус, а также комментарии из карточки. По \n",
       "двойному клику на поле <span style=\"color: #008000; text-decoration-color: #008000\">\"Проживающий\"</span> можно перейти в карточку проживающего.\n",
       "\n",
       "### End\n",
       "</pre>\n"
      ],
      "text/plain": [
       "### Instruction:\n",
       "Ответь на вопрос максимально точно и лаконично.\n",
       "\n",
       "### Input:\n",
       "\u001b[1;36m2\u001b[0m. Какие данные можно увидеть в нижней части обработки «Карта номерного фонда»?\n",
       "\n",
       "### Response:\n",
       "- В нижней части обработки можно увидеть информацию о проживающем: ФИО, место работы, должность, подразделение, \n",
       "номер заявки или брони на указанный период, даты заезда и выезда, статус, а также комментарии из карточки. По \n",
       "двойному клику на поле \u001b[32m\"Проживающий\"\u001b[0m можно перейти в карточку проживающего.\n",
       "\n",
       "### End\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iloc=240\n",
    "q=df.loc[iloc, 'text']\n",
    "print(q)\n",
    "#print(df.loc[iloc, 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "272045af-71f7-493c-8d3b-14ebd61b3a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Какие кнопки используются для групповой обработки задач на форме списка задач?\n",
    "q='Какие рекомендации по решению ситуации с выводом вагонов без внешнего суточного задания?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "784e3eb2-bd03-48f4-84a5-b8963856f399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">### Instruction: Ответь на вопрос максимально точно и лаконично.\n",
       "\n",
       "### Input: Какие рекомендации по решению ситуации с выводом вагонов без внешнего суточного задания?\n",
       "\n",
       "### Response: Рекомендация <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: Если причиной выхода вагонов без внешнего задания является отсутствие связей в \n",
       "таблице «Выгрузка/Связь», то необходимо установить все новые связи, которые были бы установлены после запуска \n",
       "заданий для этого дня <span style=\"font-weight: bold\">(</span>временная дата согласуется с текущей датой<span style=\"font-weight: bold\">)</span>. Рекомендация <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: После того, как будут \n",
       "установлены все новые связи, следует перезаписать целительную группу из командной области и пересоздать задание \n",
       "«Дневное распределение».\n",
       "\n",
       "### End:\n",
       "Окончание\n",
       "\n",
       "### EndResponse:\n",
       "Закрывающее сообщение\n",
       "\n",
       "### EndInput:\n",
       "Конечный инPUT\n",
       "\n",
       "### EndInstruction:\n",
       "Концовый INSTRУ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "### Instruction: Ответь на вопрос максимально точно и лаконично.\n",
       "\n",
       "### Input: Какие рекомендации по решению ситуации с выводом вагонов без внешнего суточного задания?\n",
       "\n",
       "### Response: Рекомендация \u001b[1;36m1\u001b[0m: Если причиной выхода вагонов без внешнего задания является отсутствие связей в \n",
       "таблице «Выгрузка/Связь», то необходимо установить все новые связи, которые были бы установлены после запуска \n",
       "заданий для этого дня \u001b[1m(\u001b[0mвременная дата согласуется с текущей датой\u001b[1m)\u001b[0m. Рекомендация \u001b[1;36m2\u001b[0m: После того, как будут \n",
       "установлены все новые связи, следует перезаписать целительную группу из командной области и пересоздать задание \n",
       "«Дневное распределение».\n",
       "\n",
       "### End:\n",
       "Окончание\n",
       "\n",
       "### EndResponse:\n",
       "Закрывающее сообщение\n",
       "\n",
       "### EndInput:\n",
       "Конечный инPUT\n",
       "\n",
       "### EndInstruction:\n",
       "Концовый INSTRУ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Time taken for inference: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.32</span> seconds\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Time taken for inference: \u001b[1;36m9.32\u001b[0m seconds\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#inference on test data example\n",
    "from time import perf_counter\n",
    "from rich import print\n",
    "from transformers import GenerationConfig\n",
    "#text = test_df['text'][4]\n",
    "text=f'<s>### Instruction: Ответь на вопрос максимально точно и лаконично.\\n\\n### Input: {q}\\n\\n### Response:'\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to('cuda')\n",
    "generation_config = GenerationConfig(\n",
    "    penalty_alpha=1, \n",
    "    do_sample = True, \n",
    "    top_k=10, \n",
    "    temperature=0.3, \n",
    "    repetition_penalty=1.2,\n",
    "    max_new_tokens=200\n",
    ")\n",
    "start_time = perf_counter()\n",
    "outputs = persisted_model.generate(**inputs, generation_config=generation_config, pad_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "end_time = perf_counter()\n",
    "output_time = end_time - start_time\n",
    "print(f\"Time taken for inference: {round(output_time,2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7a78b3fa-9f91-4745-b42d-0f4a7cebe43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Какие рекомендации по решению ситуации с выводом вагонов без внешнего суточного задания?\n",
       "Ответ: Регистрировать причинение и освобождение путей под управлением, а также запуска/остановку движения в \n",
       "регистре «Собственные события» <span style=\"font-weight: bold\">(</span>кнопка «Записать»<span style=\"font-weight: bold\">)</span>. После этого необходимо перезагрузиться системой. При этом \n",
       "система автоматически удалила все добавленное после последней версии файлы константы \n",
       "REGION_VARIABLES\\VL-DATA\\STATION\\_DEPOT and VL-DATA\\STAFF\\_EMPLOYEE, что может повлияет на работу системы..\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Какие рекомендации по решению ситуации с выводом вагонов без внешнего суточного задания?\n",
       "Ответ: Регистрировать причинение и освобождение путей под управлением, а также запуска/остановку движения в \n",
       "регистре «Собственные события» \u001b[1m(\u001b[0mкнопка «Записать»\u001b[1m)\u001b[0m. После этого необходимо перезагрузиться системой. При этом \n",
       "система автоматически удалила все добавленное после последней версии файлы константы \n",
       "REGION_VARIABLES\\VL-DATA\\STATION\\_DEPOT and VL-DATA\\STAFF\\_EMPLOYEE, что может повлияет на работу системы..\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Time taken for inference: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.44</span> seconds\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Time taken for inference: \u001b[1;36m6.44\u001b[0m seconds\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = q+\"\\nОтвет:\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to('cuda')\n",
    "generation_config = GenerationConfig(\n",
    "    penalty_alpha=1, \n",
    "    do_sample = True, \n",
    "    top_k=2, \n",
    "    temperature=0.2, \n",
    "    repetition_penalty=1.5,\n",
    "    max_new_tokens=400\n",
    ")\n",
    "start_time = perf_counter()\n",
    "outputs = persisted_model.generate(**inputs, generation_config=generation_config, pad_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "end_time = perf_counter()\n",
    "output_time = end_time - start_time\n",
    "print(f\"Time taken for inference: {round(output_time,2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3560dc66-f1ec-423b-9a34-3990b07596a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e8a822-9eee-475b-9d9d-89c2824e65be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d507b94d-2cfe-45d3-8b38-e9b2d58a5b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa528a-e32a-479a-b9f8-dac25aa15799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c49e0df-3f52-4ed7-9fb9-27ebd36eb135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17422d9d-8a0b-4262-befc-fd38e37d361a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
