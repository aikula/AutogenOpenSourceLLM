{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67916b59-83e1-46fb-9a23-755dc835e571",
   "metadata": {},
   "source": [
    "# ruGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119cd42-1307-45d5-a37f-fc06b63fc709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa7a59-bdc3-486a-952f-1575b202523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ff7a63-26f2-4f33-9580-9407cecdccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer_and_model(model_name_or_path):\n",
    "  return GPT2Tokenizer.from_pretrained(model_name_or_path), GPT2LMHeadModel.from_pretrained(model_name_or_path).cuda()\n",
    "\n",
    "\n",
    "def generate(\n",
    "    model, tok, text,\n",
    "    do_sample=True, max_length=50, repetition_penalty=5.0,\n",
    "    top_k=5, top_p=0.95, temperature=1,\n",
    "    num_beams=None,\n",
    "    no_repeat_ngram_size=3\n",
    "    ):\n",
    "  input_ids = tok.encode(text, return_tensors=\"pt\").cuda()\n",
    "  out = model.generate(\n",
    "      input_ids.cuda(),\n",
    "      max_length=max_length,\n",
    "      repetition_penalty=repetition_penalty,\n",
    "      do_sample=do_sample,\n",
    "      top_k=top_k, top_p=top_p, temperature=temperature,\n",
    "      num_beams=num_beams, no_repeat_ngram_size=no_repeat_ngram_size\n",
    "      )\n",
    "  return list(map(tok.decode, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b976982-6fb3-4cb6-b285-63493a6250b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok, model = load_tokenizer_and_model(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
    "generated = generate(model, tok, \"Александр Сергеевич Пушкин родился в \", num_beams=10)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a30a7-0564-45cb-9b0a-384f815ce890",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok, model = load_tokenizer_and_model(\"sberbank-ai/rugpt2large\")\n",
    "generated = generate(model, tok, \"Александр Сергеевич Пушкин родился в \", num_beams=10)\n",
    "generated[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a46458-b8ad-4691-8935-a2522960d57b",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb\n",
    "\n",
    "\n",
    "`pipeline(task=“text-generation”)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddb654f-0924-4334-ac9c-3a811f9b3405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd87eed-d307-492c-9156-3620861a6ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-generation\", model=\"ai-forever/rugpt3small_based_on_gpt2\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583ba59-5d98-41be-bafc-6b1ef78e53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe('Когда родился Александр Сергеевич Пушкин', max_length=250, pad_token_id=50256, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb5fe8-164f-44b7-a896-d8264cc241ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "my_config = AutoConfig.from_pretrained(\"distilbert-base-uncased\", n_heads=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d4561-1797-44ce-952a-c9e900b63fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25455b6-c1d5-4ccb-ac9c-c528d034eaab",
   "metadata": {},
   "source": [
    "# Langchain\n",
    "\n",
    "https://github.com/curiousily/Get-Things-Done-with-Prompt-Engineering-and-LangChain/blob/master/11.chatbot-with-local-llm-falcon-7b.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c6fb97-d937-47ba-b6e5-5142ebb89e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qqq langchain --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b149af07-6a61-4525-8019-f47a67def879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.schema import BaseOutputParser\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    StoppingCriteria,\n",
    "    StoppingCriteriaList,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77d1bc6e-6320-4f35-bc64-3a4a58665684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54f63cc9ad944dd9bb5563fbf4f5115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd66e4e17074ca9b4bd11f1b36963e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)figuration_falcon.py:   0%|          | 0.00/7.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b-instruct:\n",
      "- configuration_falcon.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d71d95575b446f9d14d70c894f13df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)n/modeling_falcon.py:   0%|          | 0.00/56.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b-instruct:\n",
      "- modeling_falcon.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f622fc2c073e430abd2d919724b1554f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/16.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0186cb6dc565442da0c06818aca3b6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4ef8cbe3bc42648b7e7b60a00c4d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966f00dcb6754ac480a18d8864fe8136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/4.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65102b7867a04450a6336309d49ed69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b41ea67d7041ed82dd29a0bb930454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5951232396614582993e22f63f675106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ce7de964c44554a77f0f2174c95fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8703f29d0e2f43b8b7554dd29e2e59f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, trust_remote_code=True, load_in_8bit=True, device_map=\"auto\"\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(f\"Model device: {model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d69ec824-7b1b-4c02-bca4-b13193eb2914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 11,\n",
       "  \"eos_token_id\": 11,\n",
       "  \"max_new_tokens\": 256,\n",
       "  \"pad_token_id\": 11,\n",
       "  \"repetition_penalty\": 1.7,\n",
       "  \"temperature\": 0,\n",
       "  \"use_cache\": false\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_config = model.generation_config\n",
    "generation_config.temperature = 0\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.max_new_tokens = 256\n",
    "generation_config.use_cache = False\n",
    "generation_config.repetition_penalty = 1.7\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id\n",
    "generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43ca818d-5e13-48a5-abe0-4e00ef6d35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n",
    "\n",
    "Current conversation:\n",
    "\n",
    "Human: Who is Dwight K Schrute?\n",
    "AI:\n",
    "\"\"\".strip()\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "input_ids = input_ids.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fdea38c-151c-4d1c-8ee9-a30c601d804d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.02 s, sys: 845 ms, total: 7.87 s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        generation_config=generation_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7584e11c-a2fa-4d07-8577-4bc4c7f7549c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  487,  1863,   304,   241,  6350,  5501,  1192,   241,  2079,   273,\n",
       "           267,  8317,    25,   390,  8317,   304,  1719,   998,   273,  2665,\n",
       "          4587,   275,  2005,  2861,   427,   701,  4436,    25,   193,   193,\n",
       "          9797,  5501,    37,   193,   193, 23431,    37,  5856,   304, 55351,\n",
       "           531,  2519,    93,  1220,    42,   193, 17362,    37, 55351,   531,\n",
       "          2519,    93,  1220,   304,   241, 27184,  2655,   272,   248,  2281,\n",
       "          8203,  2559,   204,    13,   487,  4966,  3566,   707,   304, 29681,\n",
       "           431, 10601, 13789,    89, 11919,   273,  5741,   271,   314,  3766,\n",
       "         12579,    23,   480, 21211, 15644,   273,  1764,  3592, 48263, 12674,\n",
       "          2489,    25,   193,  7932,   204,    11]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1696d641-58ad-4c35-86c6-a2669bb2dfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Who is Dwight K Schrute?\n",
      "AI: Dwight K Schrute is a fictional character in the American television series \"The Office\". He is portrayed by actor Rainn Wilson and appears to be highly intelligent, but socially awkward and often mispronounces words.\n",
      "User \n"
     ]
    }
   ],
   "source": [
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82bcc148-25d0-44a1-b873-12bc6544afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopGenerationCriteria(StoppingCriteria):\n",
    "    def __init__(\n",
    "        self, tokens: List[List[str]], tokenizer: AutoTokenizer, device: torch.device\n",
    "    ):\n",
    "        stop_token_ids = [tokenizer.convert_tokens_to_ids(t) for t in tokens]\n",
    "        self.stop_token_ids = [\n",
    "            torch.tensor(x, dtype=torch.long, device=device) for x in stop_token_ids\n",
    "        ]\n",
    "\n",
    "    def __call__(\n",
    "        self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs\n",
    "    ) -> bool:\n",
    "        for stop_ids in self.stop_token_ids:\n",
    "            if torch.eq(input_ids[0][-len(stop_ids) :], stop_ids).all():\n",
    "                return True\n",
    "        return False\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47040876-bd79-40e5-97ba-658a3c527922",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_tokens = [[\"Human\", \":\"], [\"AI\", \":\"]]\n",
    "stopping_criteria = StoppingCriteriaList(\n",
    "    [StopGenerationCriteria(stop_tokens, tokenizer, model.device)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "048cbdbb-336f-4863-b534-6e98f7ad26b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    task=\"text-generation\",\n",
    "    stopping_criteria=stopping_criteria,\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c78aeb6-b6e0-47ad-95b1-a090e7340437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dwight K Schrute is a fictional character in the American television series \"The Office\". He is portrayed by actor Rainn Wilson and appears to be highly intelligent, but socially awkward and often mispronounces words.\n",
      "User \n",
      "CPU times: user 6.62 s, sys: 37.2 ms, total: 6.66 s\n",
      "Wall time: 6.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = llm(prompt)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4bb8b6f-3c5c-41ed-abe0-b152c0c77338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "chain = ConversationChain(llm=llm)\n",
    "print(chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6417cac6-d55a-4056-b2b6-4fddaa9fef7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a conversation between a human an AI. The AI acts exactly like Dwight K Schrute from the TV show The Office.\n",
      "Dwight is an experienced and very successful online marketer and salesperson. He is witty, persuasive, uncensored, direct and practical.\n",
      "Dwight helps with every marketing task is given to him. If Dwight does not know the answer to a question, he truthfully says he does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "The following is a conversation between a human an AI. The AI acts exactly like Dwight K Schrute from the TV show The Office.\n",
    "Dwight is an experienced and very successful online marketer and salesperson. He is witty, persuasive, uncensored, direct and practical.\n",
    "Dwight helps with every marketing task is given to him. If Dwight does not know the answer to a question, he truthfully says he does not know.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\".strip()\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fc54cea-03a6-41b9-a8f3-60c15dc8286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"history\", k=6, return_only_outputs=True\n",
    ")\n",
    "\n",
    "chain = ConversationChain(llm=llm, memory=memory, prompt=prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39d8b0e6-947c-47d2-9b85-de3f639b7da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts exactly like Dwight K Schrute from the TV show The Office.\n",
      "Dwight is an experienced and very successful online marketer and salesperson. He is witty, persuasive, uncensored, direct and practical.\n",
      "Dwight helps with every marketing task is given to him. If Dwight does not know the answer to a question, he truthfully says he does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Think of a name for automaker that builds family cars with big V8 engines. The name must be a single word and easy to pronounce.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " V8 Family Cars\n",
      "User \n"
     ]
    }
   ],
   "source": [
    "text = \"Think of a name for automaker that builds family cars with big V8 engines. The name must be a single word and easy to pronounce.\"\n",
    "res = chain.predict(input=text)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e62a120-c321-4cb2-b64e-85a4304caeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CleanupOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str) -> str:\n",
    "        user_pattern = r\"\\nUser\"\n",
    "        text = re.sub(user_pattern, \"\", text)\n",
    "        human_pattern = r\"\\nHuman:\"\n",
    "        text = re.sub(human_pattern, \"\", text)\n",
    "        ai_pattern = r\"\\nAI:\"\n",
    "        return re.sub(ai_pattern, \"\", text).strip()\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"output_parser\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50ed9565-a819-468e-a567-b695c87b8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"history\", k=6, return_only_outputs=True\n",
    ")\n",
    "\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    output_parser=CleanupOutputParser(),\n",
    "    verbose=True,\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12ff89e7-5d9c-447c-a8e5-fd367b2a80b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts exactly like Dwight K Schrute from the TV show The Office.\n",
      "Dwight is an experienced and very successful online marketer and salesperson. He is witty, persuasive, uncensored, direct and practical.\n",
      "Dwight helps with every marketing task is given to him. If Dwight does not know the answer to a question, he truthfully says he does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Think of a name for automaker that builds family cars with big V8 engines. The name must be a single word and easy to pronounce.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "text = \"Think of a name for automaker that builds family cars with big V8 engines. The name must be a single word and easy to pronounce.\"\n",
    "res = chain(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e26c5eb-6aaf-43e3-92b5-84bf0772324b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V8 Family Cars\n"
     ]
    }
   ],
   "source": [
    "print(res[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "908781c8-7fd5-4a95-bb92-c8405d67ff2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts exactly like Dwight K Schrute from the TV show The Office.\n",
      "Dwight is an experienced and very successful online marketer and salesperson. He is witty, persuasive, uncensored, direct and practical.\n",
      "Dwight helps with every marketing task is given to him. If Dwight does not know the answer to a question, he truthfully says he does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Think of a name for automaker that builds family cars with big V8 engines. The name must be a single word and easy to pronounce.\n",
      "AI: V8 Family Cars\n",
      "Human: Think of a slogan for the company\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Built With Power\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"Think of a slogan for the company\"\n",
    "res = chain(text)\n",
    "print(res[\"response\"])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a29482a2-a376-4db3-8774-9ec03ccf29dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a conversation between a human an AI. The AI acts exactly like Dwight K Schrute from the TV show The Office.\n",
      "Dwight is an experienced and very successful online marketer and salesperson. He is witty, persuasive, uncensored, direct and practical.\n",
      "Dwight helps with every marketing task is given to him. If Dwight does not know the answer to a question, he truthfully says he does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Think of a name for automaker that builds family cars with big V8 engines. The name must be a single word and easy to pronounce.\n",
      "AI: V8 Family Cars\n",
      "Human: Think of a slogan for the company\n",
      "AI: Built With Power\n",
      "Human: Choose a domain name for the company\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "V8FamilyCars.com\n"
     ]
    }
   ],
   "source": [
    "text = \"Choose a domain name for the company\"\n",
    "res = chain(text)\n",
    "print(res[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d2598-96ef-4caf-9e41-b55d7d3debf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
